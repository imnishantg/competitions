{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-26T15:40:49.217038Z",
     "iopub.status.busy": "2020-10-26T15:40:49.216179Z",
     "iopub.status.idle": "2020-10-26T15:41:22.856217Z",
     "shell.execute_reply": "2020-10-26T15:41:22.854445Z"
    },
    "papermill": {
     "duration": 33.674682,
     "end_time": "2020-10-26T15:41:22.856366",
     "exception": false,
     "start_time": "2020-10-26T15:40:49.181684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdcm/\r\n",
      "gdcm/conda-4.8.4-py37hc8dfbb8_2.tar.bz2\r\n",
      "gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2\r\n",
      "gdcm/libjpeg-turbo-2.0.3-h516909a_1.tar.bz2\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\b/ \b\bdone\r\n",
      "Executing transaction: \\ \b\bdone\r\n"
     ]
    }
   ],
   "source": [
    "!cp ../input/gdcm-conda-install/gdcm.tar .\n",
    "!tar -xvzf gdcm.tar\n",
    "!conda install --offline ./gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:22.916926Z",
     "iopub.status.busy": "2020-10-26T15:41:22.916215Z",
     "iopub.status.idle": "2020-10-26T15:41:22.920544Z",
     "shell.execute_reply": "2020-10-26T15:41:22.921061Z"
    },
    "papermill": {
     "duration": 0.036317,
     "end_time": "2020-10-26T15:41:22.921274",
     "exception": false,
     "start_time": "2020-10-26T15:41:22.884957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:22.984039Z",
     "iopub.status.busy": "2020-10-26T15:41:22.983305Z",
     "iopub.status.idle": "2020-10-26T15:41:26.995724Z",
     "shell.execute_reply": "2020-10-26T15:41:26.995003Z"
    },
    "papermill": {
     "duration": 4.048111,
     "end_time": "2020-10-26T15:41:26.995867",
     "exception": false,
     "start_time": "2020-10-26T15:41:22.947756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from os import path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler # for training only, need nightly build pytorch\n",
    "\n",
    "import pydicom\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "from albumentations import Compose, HorizontalFlip, VerticalFlip, RandomRotate90\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.069452Z",
     "iopub.status.busy": "2020-10-26T15:41:27.068323Z",
     "iopub.status.idle": "2020-10-26T15:41:27.071152Z",
     "shell.execute_reply": "2020-10-26T15:41:27.071661Z"
    },
    "papermill": {
     "duration": 0.048202,
     "end_time": "2020-10-26T15:41:27.071826",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.023624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configurations\n",
    "img_inp = { 'b0' : 224, \n",
    "            'b1' : 240, \n",
    "            'b2' : 260, \n",
    "            'b3' : 300, \n",
    "            'b4' : 380, \n",
    "            'b5' : 456, \n",
    "            'b6' : 528, \n",
    "            'b7' : 600}\n",
    "\n",
    "\n",
    "pretrained_model = {\n",
    "    'efficientnet-b0': '../input/efficientnet-pytorch/efficientnet-b0-08094119.pth',\n",
    "    'efficientnet-b1': '../input/efficientnet-pytorch/efficientnet-b1-dbc7070a.pth', \n",
    "    'efficientnet-b2': '../input/efficientnet-pytorch/efficientnet-b2-27687264.pth',\n",
    "    'efficientnet-b3': '../input/efficientnet-pytorch/efficientnet-b3-c8376fa2.pth', \n",
    "    'efficientnet-b4': '../input/efficientnet-pytorch/efficientnet-b4-e116e8b3.pth',\n",
    "    'efficientnet-b5': '../input/efficientnet-pytorch/efficientnet-b5-586e6cc6.pth', \n",
    "    'efficientnet-b6': '../input/efficientnet-pytorch/efficientnet-b6-c76e70fd.pth',\n",
    "    'efficientnet-b7': '../input/efficientnet-pytorch/efficientnet-b7-dcc49843.pth', \n",
    "}\n",
    "\n",
    "\n",
    "CFG = {\n",
    "    'train': False,\n",
    "    \n",
    "    'train_img_path': '../input/rsna-str-pulmonary-embolism-detection/train',\n",
    "    'test_img_path': '../input/rsna-str-pulmonary-embolism-detection/test',\n",
    "    'cv_fold_path': '../input/samplersna/rsna_train_splits_fold_20.csv',\n",
    "    'train_path': '../input/rsna-str-pulmonary-embolism-detection/train.csv',\n",
    "    'test_path': '../input/rsna-str-pulmonary-embolism-detection/test.csv',\n",
    "    \n",
    "    'image_target_cols': [\n",
    "        'pe_present_on_image',\n",
    "         ],\n",
    "    \n",
    "    'exam_target_cols': [\n",
    "        'negative_exam_for_pe', \n",
    "        'indeterminate', \n",
    "        'both_no', # Added new column\n",
    "        \n",
    "        'rv_lv_ratio_gte_1', \n",
    "        'rv_lv_ratio_lt_1', \n",
    "        \n",
    "        'chronic_pe', \n",
    "        'acute_and_chronic_pe',\n",
    "        'acute_pe',  # Added new column\n",
    "        \n",
    "        'leftsided_pe',\n",
    "        'central_pe', \n",
    "        'rightsided_pe',\n",
    "        ], \n",
    "    \n",
    "    'interim_target_cols': [\n",
    "        'pe_present_on_image',\n",
    "        'negative_exam_for_pe', \n",
    "        'indeterminate', \n",
    "        'both_no', # Added new column\n",
    "        \n",
    "        'rv_lv_ratio_gte_1', \n",
    "        'rv_lv_ratio_lt_1', \n",
    "        \n",
    "        'chronic_pe', \n",
    "        'acute_and_chronic_pe',\n",
    "        'acute_pe',  # Added new column\n",
    "        \n",
    "        'leftsided_pe',\n",
    "        'central_pe', \n",
    "        'rightsided_pe',\n",
    "        \n",
    "        'qa_motion',\n",
    "        'qa_contrast',\n",
    "        'flow_artifact',\n",
    "        'true_filling_defect_not_pe'\n",
    "        ], \n",
    "   \n",
    "    \n",
    "    'lr': 0.00005,\n",
    "    'epochs': 1,\n",
    "    'device': 'cuda', # cuda, cpu\n",
    "    'train_bs': 8,\n",
    "    'valid_bs': 8,\n",
    "    'stage1_valid_bs': 256, \n",
    "    'accum_iter': 1,\n",
    "    'verbose_step': 1,\n",
    "    'num_workers': 0,\n",
    "    'efbnet': 'efficientnet-b3',  # change here\n",
    "    'img_num': 256, \n",
    "    'img_size': 300,              # change here\n",
    "    'effnet_fc': 128, \n",
    "    'metadata_feats': 26,  \n",
    "    \n",
    "    'train_folds': [\n",
    "                    # [1, 2, 3, 4], \n",
    "                    # [0, 2, 3, 4], \n",
    "                    # [0, 1, 3, 4], \n",
    "                    # [0, 1, 2, 4], \n",
    "                    [5]\n",
    "                   ], \n",
    "    \n",
    "    'valid_folds': [\n",
    "                    # [0], \n",
    "                    # [1], \n",
    "                    # [2], \n",
    "                    # [3], \n",
    "                    [6]\n",
    "                   ], \n",
    "    \n",
    "    'stage_model_path': '../input/rsna-pre-models/',\n",
    "    'model_path': '../working/',\n",
    "    'tag': 'stage2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.133885Z",
     "iopub.status.busy": "2020-10-26T15:41:27.132967Z",
     "iopub.status.idle": "2020-10-26T15:41:27.137497Z",
     "shell.execute_reply": "2020-10-26T15:41:27.136914Z"
    },
    "papermill": {
     "duration": 0.038786,
     "end_time": "2020-10-26T15:41:27.137624",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.098838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.205199Z",
     "iopub.status.busy": "2020-10-26T15:41:27.203504Z",
     "iopub.status.idle": "2020-10-26T15:41:27.205969Z",
     "shell.execute_reply": "2020-10-26T15:41:27.206531Z"
    },
    "papermill": {
     "duration": 0.041619,
     "end_time": "2020-10-26T15:41:27.206682",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.165063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pre-process train df\n",
    "def preprocess_DF(df):\n",
    "    both_no = lambda x: (1 - (x.negative_exam_for_pe + x.indeterminate))\n",
    "    acute_pe = lambda x: (1 - (x.chronic_pe + x.acute_and_chronic_pe))\n",
    "    \n",
    "    df['both_no'] = df.apply(both_no, axis=1)\n",
    "    df['acute_pe'] = df.apply(acute_pe, axis=1)\n",
    "    df['acute_pe'] = np.where(df['both_no']==0, 0, df['acute_pe'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.297879Z",
     "iopub.status.busy": "2020-10-26T15:41:27.294861Z",
     "iopub.status.idle": "2020-10-26T15:41:27.298766Z",
     "shell.execute_reply": "2020-10-26T15:41:27.299399Z"
    },
    "papermill": {
     "duration": 0.06511,
     "end_time": "2020-10-26T15:41:27.299571",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.234461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get image + pre-processing\n",
    "\n",
    "def window(img, WL=50, WW=350):\n",
    "    upper, lower = WL+WW//2, WL-WW//2\n",
    "    X = np.clip(img.copy(), lower, upper)\n",
    "    X = X - np.min(X)\n",
    "    X = X / np.max(X)\n",
    "    return X\n",
    "\n",
    "def get_img(path):\n",
    "    '''\n",
    "    # min_: patient level pixel min\n",
    "    # max_: patient level pixel max\n",
    "    \n",
    "    RED channel / LUNG window / level=-600, width=1500\n",
    "    GREEN channel / PE window / level=100, width=700\n",
    "    BLUE channel / MEDIASTINAL window / level=40, width=400\n",
    "    '''\n",
    "    d = pydicom.read_file(path)\n",
    "    \n",
    "    # Get image\n",
    "    img = (d.pixel_array * d.RescaleSlope) + d.RescaleIntercept\n",
    "    r = window(img, -600, 1500)\n",
    "    g = window(img, 100, 700)\n",
    "    b = window(img, 40, 400)\n",
    "    \n",
    "    res = np.concatenate([r[:, :, np.newaxis],\n",
    "                          g[:, :, np.newaxis],\n",
    "                          b[:, :, np.newaxis]], axis=-1)\n",
    "    \n",
    "    res = zoom(res, [CFG['img_size']/res.shape[0], CFG['img_size']/res.shape[1], 1.], prefilter=False, order=1) \n",
    "    \n",
    "    # Get numerical metadata\n",
    "    SliceThickness           = float(d.SliceThickness)\n",
    "    KVP                      = float(d.KVP)/100.0\n",
    "    TableHeight              = float(d.TableHeight)/100.0\n",
    "    XRayTubeCurrent          = float(d.XRayTubeCurrent)/100.0\n",
    "    Exposure                 = float(d.Exposure)/100.0\n",
    "    GantryDetectorTilt       = float(d.GantryDetectorTilt)\n",
    "\n",
    "    ImagePositionPatient     = [x/100.0 for x in list(d.ImagePositionPatient)]\n",
    "    ImageOrientationPatient  = list(d.ImageOrientationPatient)\n",
    "    \n",
    "    mt_num = np.array((SliceThickness, KVP, TableHeight, \n",
    "                XRayTubeCurrent, Exposure, \n",
    "                *ImagePositionPatient, *ImageOrientationPatient, \n",
    "                GantryDetectorTilt))\n",
    "\n",
    "    # Get categorical metadata\n",
    "    SpecificCharacterSet = d.SpecificCharacterSet\n",
    "    ImageType            = d.ImageType\n",
    "    ConvolutionKernel    = d.ConvolutionKernel\n",
    "    PatientPosition      = d.PatientPosition\n",
    "    \n",
    "    sps_100     = np.where(SpecificCharacterSet=='ISO_IR 100', 1, 0)\n",
    "    sps_other   = np.where(sps_100==0, 1, 0)\n",
    "\n",
    "    it_opa      = np.where(ImageType==\"['ORIGINAL', 'PRIMARY', 'AXIAL']\", 1, 0)\n",
    "    it_o        = np.where(ImageType==\"ORIGINAL\", 1, 0)\n",
    "    it_other    = np.where(it_opa+it_o > 0, 0, 1)\n",
    "\n",
    "    ck_std      = np.where(ConvolutionKernel==\"STANDARD\", 1, 0)\n",
    "    ck_b        = np.where(ConvolutionKernel==\"B\", 1, 0)\n",
    "    ck_other    = np.where(ck_std+ck_b > 0, 0, 1)\n",
    "\n",
    "    pp_ffs      = np.where(PatientPosition==\"FFS\", 1, 0)\n",
    "    pp_hfs      = np.where(PatientPosition==\"HFS\", 1, 0)\n",
    "    pp_other    = np.where(pp_ffs+pp_hfs > 0, 0, 1)\n",
    "    \n",
    "    mt_cat = np.array((sps_100, sps_other, it_opa, it_o, it_other, ck_std, ck_b, ck_other, pp_ffs, pp_hfs, pp_other))\n",
    "    \n",
    "    # Get Metadata\n",
    "    mt = np.concatenate((mt_num, mt_cat))\n",
    "    \n",
    "    return res, mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.373552Z",
     "iopub.status.busy": "2020-10-26T15:41:27.370626Z",
     "iopub.status.idle": "2020-10-26T15:41:27.376944Z",
     "shell.execute_reply": "2020-10-26T15:41:27.376337Z"
    },
    "papermill": {
     "duration": 0.049061,
     "end_time": "2020-10-26T15:41:27.377096",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.328035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RSNADatasetStage1(TensorDataset):\n",
    "    def __init__(\n",
    "        self, df, label_smoothing, data_root, \n",
    "        image_subsampling=True, transforms=None, output_label=True\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.df[CFG['image_target_cols']].values[index]\n",
    "            \n",
    "        path = \"{}/{}/{}/{}.dcm\".format(self.data_root, \n",
    "                                        self.df.iloc[index]['StudyInstanceUID'], \n",
    "                                        self.df.iloc[index]['SeriesInstanceUID'], \n",
    "                                        self.df.iloc[index]['SOPInstanceUID'])\n",
    "        \n",
    "        img, mt  = get_img(path)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        # do label smoothing\n",
    "        if self.output_label == True:\n",
    "            target = np.clip(target, self.label_smoothing, 1 - self.label_smoothing)\n",
    "            \n",
    "            return img, mt, target\n",
    "        else:\n",
    "            return img, mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.470351Z",
     "iopub.status.busy": "2020-10-26T15:41:27.447056Z",
     "iopub.status.idle": "2020-10-26T15:41:27.472829Z",
     "shell.execute_reply": "2020-10-26T15:41:27.473392Z"
    },
    "papermill": {
     "duration": 0.068692,
     "end_time": "2020-10-26T15:41:27.473572",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.404880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RSNADataset(TensorDataset):\n",
    "    def __init__(\n",
    "        self, df, label_smoothing, data_root, \n",
    "        image_subsampling=True, transforms=None, output_label=True\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.patients = self.df['StudyInstanceUID'].unique()\n",
    "        self.image_subsampling = image_subsampling\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "        \n",
    "    def get_patients(self):\n",
    "        return self.patients\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.patients)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        patient = self.patients[index]\n",
    "        df_ = self.df.loc[self.df.StudyInstanceUID == patient]\n",
    "        \n",
    "        per_image_feats = get_stage1_columns()\n",
    "        #print(per_image_feats)\n",
    "        \n",
    "        if self.image_subsampling:\n",
    "            img_num = min(CFG['img_num'], df_.shape[0])\n",
    "            \n",
    "            # naive image subsampling\n",
    "            img_ix = np.random.choice(np.arange(df_.shape[0]), replace=False, size=img_num)\n",
    "            \n",
    "            # get all images, then slice location and sort according to z values\n",
    "            \n",
    "            imgs = np.zeros((CFG['img_num'],), np.float32)\n",
    "            # mts = np.zeros((CFG['img_num'],), np.float32)\n",
    "            per_image_preds = np.zeros((CFG['img_num'], len(per_image_feats)), np.float32)\n",
    "            locs = np.zeros((CFG['img_num'],), np.float32)\n",
    "            image_masks = np.zeros((CFG['img_num'],), np.float32)\n",
    "            image_masks[:img_num] = 1.\n",
    "            \n",
    "            # get labels -- TODO - maybe get rid of image labels\n",
    "            if self.output_label:\n",
    "                exam_label = df_[CFG['exam_target_cols']].values[0]\n",
    "                image_labels = np.zeros((CFG['img_num'], len(CFG['image_target_cols'])), np.float32)\n",
    "            \n",
    "        else:\n",
    "            img_num = df_.shape[0]\n",
    "            img_ix = np.arange(df_.shape[0])\n",
    "            \n",
    "            # get all images, then slice location and sort according to z values\n",
    "            imgs = np.zeros((img_num, ), np.float32)\n",
    "            # mts = np.zeros((img_num, ), np.float32)\n",
    "            per_image_preds = np.zeros((img_num, len(per_image_feats)), np.float32)\n",
    "            locs = np.zeros((img_num,), np.float32)\n",
    "            image_masks = np.zeros((img_num,), np.float32)\n",
    "            image_masks[:img_num] = 1.\n",
    "            \n",
    "            # get labels -- TODO - maybe get rid of image labels\n",
    "            if self.output_label:\n",
    "                exam_label = df_[CFG['exam_target_cols']].values[0]\n",
    "                image_labels = np.zeros((img_num, len(CFG['image_target_cols'])), np.float32)\n",
    "                \n",
    "        for i, im_ix in enumerate(img_ix):\n",
    "            path = \"{}/{}/{}/{}.dcm\".format(self.data_root, \n",
    "                                            df_['StudyInstanceUID'].values[im_ix], \n",
    "                                            df_['SeriesInstanceUID'].values[im_ix], \n",
    "                                            df_['SOPInstanceUID'].values[im_ix])\n",
    "            \n",
    "            d = pydicom.read_file(path)\n",
    "            \n",
    "            locs[i] = d.ImagePositionPatient[2]\n",
    "            per_image_preds[i,:] = df_[per_image_feats].values[im_ix,:]\n",
    "            \n",
    "            if self.output_label == True:\n",
    "                image_labels[i] = df_[CFG['image_target_cols']].values[im_ix]\n",
    "\n",
    "        #print('get img done')\n",
    "        \n",
    "        seq_ix = np.argsort(locs)\n",
    "        \n",
    "        # image features: img_num * img_size * img_size * 1\n",
    "        '''\n",
    "        imgs = imgs[seq_ix]\n",
    "        if self.transforms:\n",
    "            imgs = [self.transforms(image=img)['image'] for img in imgs]\n",
    "        imgs = torch.stack(imgs)\n",
    "        '''\n",
    "        \n",
    "        # image level features: img_num\n",
    "        locs = locs[seq_ix]\n",
    "        locs[1:img_num] = locs[1:img_num]-locs[0:img_num-1]\n",
    "        locs[0] = 0\n",
    "        \n",
    "        per_image_preds = per_image_preds[seq_ix]\n",
    "\n",
    "        # do label smoothing\n",
    "        if self.output_label == True:\n",
    "            image_labels = image_labels[seq_ix]\n",
    "            image_labels = np.clip(image_labels, self.label_smoothing, 1 - self.label_smoothing)\n",
    "            exam_label =  np.clip(exam_label, self.label_smoothing, 1 - self.label_smoothing)\n",
    "            \n",
    "            return imgs, per_image_preds, locs, image_labels, exam_label, image_masks\n",
    "        else:\n",
    "            return imgs, per_image_preds, locs, img_num, index, seq_ix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.538545Z",
     "iopub.status.busy": "2020-10-26T15:41:27.536845Z",
     "iopub.status.idle": "2020-10-26T15:41:27.539315Z",
     "shell.execute_reply": "2020-10-26T15:41:27.539881Z"
    },
    "papermill": {
     "duration": 0.0384,
     "end_time": "2020-10-26T15:41:27.540026",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.501626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    " \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.632029Z",
     "iopub.status.busy": "2020-10-26T15:41:27.625252Z",
     "iopub.status.idle": "2020-10-26T15:41:27.635133Z",
     "shell.execute_reply": "2020-10-26T15:41:27.634515Z"
    },
    "papermill": {
     "duration": 0.067393,
     "end_time": "2020-10-26T15:41:27.635255",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.567862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.cnn_model = EfficientNet.from_pretrained(CFG['efbnet'], in_channels=3)\n",
    "        self.cnn_model = EfficientNet.from_name(CFG['efbnet'])\n",
    "        self.cnn_model.load_state_dict(torch.load(pretrained_model[CFG['efbnet']]))\n",
    "        # self.model._fc = nn.Linear(self.cnn_model._fc.in_features, CFG['effnet_fc'], bias=True)\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def get_dim(self):\n",
    "        return self.cnn_model._fc.in_features\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feats = self.cnn_model.extract_features(x)\n",
    "        return self.pooling(feats).view(x.shape[0], -1)\n",
    "\n",
    "\n",
    "class RSNAImgClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # For image\n",
    "        self.cnn_model = FeatureExtractor()\n",
    "        # For metadata\n",
    "        self.fnn_fc1 = nn.Linear(in_features=CFG['metadata_feats'], out_features=32)\n",
    "        self.fnn_fc2 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.fnn_fc3 = nn.Linear(in_features=32, out_features=16)\n",
    "        # Final Fusion\n",
    "        self.final_fc = nn.Linear(in_features=self.cnn_model.get_dim()+16, out_features=len(CFG['interim_target_cols']))\n",
    "        \n",
    "    def forward(self, imgs, mts):\n",
    "        imgs_embdes = self.cnn_model(imgs) # bs * efb_feat_size\n",
    "        mt_embed = self.fnn_fc1(mts)\n",
    "        mt_embed = self.fnn_fc2(mt_embed)\n",
    "        mt_embed = self.fnn_fc3(mt_embed)\n",
    "        \n",
    "        embed = torch.cat([imgs_embdes, mt_embed],dim=1)\n",
    "        image_preds = self.final_fc(embed)\n",
    "        return image_preds\n",
    "    \n",
    "class TimeDistributed(nn.Module):\n",
    "\n",
    "    def __init__(self, module, batch_first=True):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' x size: (batch_size, time_steps, in_channels, height, width) '''\n",
    "        x_size= x.size()\n",
    "        c_in = x.contiguous().view(x_size[0] * x_size[1], *x_size[2:])\n",
    "        \n",
    "        c_out = self.module(c_in)\n",
    "        r_in = c_out.view(x_size[0], x_size[1], -1)\n",
    "        if self.batch_first is False:\n",
    "            r_in = r_in.permute(1, 0, 2)\n",
    "        return r_in\n",
    "    \n",
    "\n",
    "class RSNAClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gru = nn.GRU(len(CFG['interim_target_cols'])+1, hidden_size, bidirectional=True, batch_first=True, num_layers=2)\n",
    "        self.image_predictors = TimeDistributed(nn.Linear(hidden_size*2, len(CFG['image_target_cols'])))\n",
    "        self.exam_predictor = nn.Linear(hidden_size*2*6, len(CFG['exam_target_cols']))\n",
    "        \n",
    "    def forward(self, img_preds, locs):\n",
    "        \n",
    "        embeds = torch.cat([img_preds, locs.view(locs.shape[0], locs.shape[1], 1)], dim=2) # bs * ts * fs\n",
    "        \n",
    "        embeds, _ = self.gru(embeds)\n",
    "        image_preds = self.image_predictors(embeds)\n",
    "        \n",
    "        max_pool, _ = torch.max(embeds, 1)\n",
    "        min_pool, _ = torch.min(embeds, 1)\n",
    "        median_pool, _ = torch.median(embeds, 1)\n",
    "        mean_pool   = torch.mean(embeds, 1)\n",
    "        std_pool    = torch.std(embeds, 1)\n",
    "        var_pool    = torch.var(embeds, 1)\n",
    "        conc = torch.cat([max_pool, min_pool, median_pool, mean_pool, std_pool, var_pool], 1)\n",
    "        \n",
    "        exam_pred = self.exam_predictor(conc)\n",
    "        \n",
    "        return image_preds, exam_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.716239Z",
     "iopub.status.busy": "2020-10-26T15:41:27.705536Z",
     "iopub.status.idle": "2020-10-26T15:41:27.742368Z",
     "shell.execute_reply": "2020-10-26T15:41:27.741703Z"
    },
    "papermill": {
     "duration": 0.079358,
     "end_time": "2020-10-26T15:41:27.742497",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.663139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rsna_wloss_inference(y_true_img, y_true_exam, y_pred_img, y_pred_exam, chunk_sizes):\n",
    "    # y_true_img, y_pred_img: (p1*in1 + p2*in2 + ,,,) \n",
    "    # y_true_exam, y_pred_exam: (p1*in1 + p2*in2 + ,,,) x 9\n",
    "    # chunk_sizes: (patient_num)\n",
    "    '''\n",
    "    'negative_exam_for_pe', # exam level 0.0736196319\n",
    "    'indeterminate' # exam level 0.09202453988\n",
    "    'both_no' # exam level 0.0000000\n",
    "    \n",
    "    'rv_lv_ratio_gte_1', # exam level 0.2346625767\n",
    "    'rv_lv_ratio_lt_1', # exam level 0.0782208589\n",
    "    \n",
    "    'chronic_pe', # exam level 0.1042944785\n",
    "    'acute_and_chronic_pe', # exam level 0.1042944785\n",
    "    'acute_pe', # exam level 0.000000\n",
    "        \n",
    "    'leftsided_pe', # exam level 0.06257668712\n",
    "    'central_pe', # exam level 0.1877300613\n",
    "    'rightsided_pe', # exam level 0.06257668712\n",
    "    '''\n",
    "    \n",
    "    # transform into torch tensors\n",
    "    y_true_img, y_true_exam, y_pred_img, y_pred_exam = torch.tensor(y_true_img, dtype=torch.float32).to(device), torch.tensor(y_true_exam, dtype=torch.float32).to(device), torch.tensor(y_pred_img, dtype=torch.float32).to(device), torch.tensor(y_pred_exam, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # split into chunks (each chunks is for a single exam)\n",
    "    y_true_img_chunks, y_true_exam_chunks, y_pred_img_chunks, y_pred_exam_chunks = torch.split(y_true_img, chunk_sizes, dim=0), torch.split(y_true_exam, chunk_sizes, dim=0), torch.split(y_pred_img, chunk_sizes, dim=0), torch.split(y_pred_exam, chunk_sizes, dim=0)\n",
    "    \n",
    "    label_w = torch.tensor([0.0736196319,  0.09202453988, 0.0000001, 0.2346625767, 0.0782208589, 0.1042944785, 0.1042944785, 0.000001, 0.06257668712, 0.1877300613, 0.06257668712]).view(1, -1).to(device)\n",
    "    img_w = torch.tensor([0.07361963]).to(device)\n",
    "    bce_func = torch.nn.BCELoss(reduction='none')\n",
    "    \n",
    "    total_loss = torch.tensor(0, dtype=torch.float32).to(device)\n",
    "    total_weights = torch.tensor(0, dtype=torch.float32).to(device)\n",
    "    for i, (y_true_img_, y_true_exam_, y_pred_img_, y_pred_exam_) in enumerate(zip(y_true_img_chunks, y_true_exam_chunks, y_pred_img_chunks, y_pred_exam_chunks)):\n",
    "        exam_loss = bce_func(y_pred_exam_[0, :], y_true_exam_[0, :])\n",
    "        exam_loss = torch.sum(exam_loss*label_w, 1)[0] # Kaggle uses a binary log loss equation for each label and then takes the mean of the log loss over all labels.\n",
    "        #print(exam_loss)\n",
    "\n",
    "        image_loss = bce_func(y_pred_img_, y_true_img_)\n",
    "        img_num = chunk_sizes[i]\n",
    "        qi = torch.sum(y_true_img_)/img_num\n",
    "        image_loss = torch.sum(img_w[0]*qi*image_loss)\n",
    "        #print(image_loss)\n",
    "    \n",
    "        total_loss += exam_loss+image_loss\n",
    "        total_weights += label_w.sum() + img_w[0]*qi*img_num\n",
    "        #assert False\n",
    "        \n",
    "    final_loss = total_loss/total_weights\n",
    "    return final_loss\n",
    "\n",
    "def rsna_wloss_train(y_true_img, y_true_exam, y_pred_img, y_pred_exam, image_masks, device):\n",
    "    # y_true_img, y_pred_img: patient_numximg_num\n",
    "    # y_true_exam, y_pred_exam: patient_num x 9\n",
    "    \n",
    "    label_w = torch.tensor([0.0736196319,  0.09202453988, 0.0000001, 0.2346625767, 0.0782208589, 0.1042944785, 0.1042944785, 0.000001, 0.06257668712, 0.1877300613, 0.06257668712]).view(1, -1).to(device)\n",
    "    img_w = torch.tensor([0.07361963]).to(device)\n",
    "    bce_func = torch.nn.BCEWithLogitsLoss(reduction='none').to(device)\n",
    "    \n",
    "    total_loss = torch.tensor(0, dtype=torch.float32).to(device)\n",
    "    total_weights = torch.tensor(0, dtype=torch.float32).to(device)\n",
    "    for i in range(y_true_img.shape[0]):\n",
    "        exam_loss = bce_func(y_pred_exam[i, :], y_true_exam[i, :])\n",
    "        exam_loss = torch.sum(exam_loss*label_w, 1)[0] # Kaggle uses a binary log loss equation for each label and then takes the mean of the log loss over all labels.\n",
    "        #print(exam_loss)\n",
    "\n",
    "        img_mask = image_masks[i]\n",
    "        #print(torch.sum(y_true_img[i,:]), torch.sum(img_mask))\n",
    "        image_loss = bce_func(y_pred_img[i,:], y_true_img[i,:]).flatten()\n",
    "        #print(image_loss.shape)\n",
    "        #print(img_mask.shape)\n",
    "        #print((image_loss*img_mask).shape)\n",
    "        #assert False\n",
    "        image_loss = image_loss*img_mask # mark 0 loss for padding images\n",
    "        img_num = torch.sum(img_mask) #y_true_img.shape[1]\n",
    "        qi = torch.sum(y_true_img[i,:])/img_num\n",
    "        image_loss = torch.sum(img_w[0]*qi*image_loss)\n",
    "        #print(image_loss)\n",
    "    \n",
    "        total_loss += exam_loss+image_loss\n",
    "        total_weights += label_w.sum() + img_w[0]*qi*img_num\n",
    "        #assert False\n",
    "        \n",
    "    final_loss = total_loss/total_weights\n",
    "    return final_loss, total_loss, total_weights\n",
    "\n",
    "def rsna_wloss_valid(y_true_img, y_true_exam, y_pred_img, y_pred_exam, image_masks, device):\n",
    "    # y_true_img, y_pred_img: patient_numximg_num\n",
    "    # y_true_exam, y_pred_exam: patient_num x 9\n",
    "    \n",
    "    label_w = torch.tensor([0.0736196319,  0.09202453988, 0.0000001, 0.2346625767, 0.0782208589, 0.1042944785, 0.1042944785, 0.000001, 0.06257668712, 0.1877300613, 0.06257668712]).view(1, -1).to(device)\n",
    "    img_w = torch.tensor([0.07361963]).to(device)\n",
    "    bce_func = torch.nn.BCEWithLogitsLoss(reduction='none').to(device)\n",
    "    \n",
    "    total_loss = torch.tensor(0, dtype=torch.float32).to(device)\n",
    "    total_weights = torch.tensor(0, dtype=torch.float32).to(device)\n",
    "    for i in range(y_true_img.shape[0]):\n",
    "        exam_loss = bce_func(y_pred_exam[i, :], y_true_exam[i, :])\n",
    "        exam_loss = torch.sum(exam_loss*label_w, 1)[0] # Kaggle uses a binary log loss equation for each label and then takes the mean of the log loss over all labels.\n",
    "        #print(exam_loss)\n",
    "\n",
    "        img_mask = image_masks[i]\n",
    "        #print(torch.sum(y_true_img[i,:]), torch.sum(img_mask))\n",
    "        image_loss = bce_func(y_pred_img[i,:], y_true_img[i,:]).flatten()\n",
    "        #print(image_loss.shape)\n",
    "        #print(img_mask.shape)\n",
    "        #print((image_loss*img_mask).shape)\n",
    "        #assert False\n",
    "        image_loss = image_loss*img_mask # mark 0 loss for padding images\n",
    "        img_num = torch.sum(img_mask) #y_true_img.shape[1]\n",
    "        qi = torch.sum(y_true_img[i,:])/img_num\n",
    "        image_loss = torch.sum(img_w[0]*qi*image_loss)\n",
    "        #print(image_loss)\n",
    "    \n",
    "        total_loss += exam_loss+image_loss\n",
    "        total_weights += label_w.sum() + img_w[0]*qi*img_num\n",
    "        #assert False\n",
    "        \n",
    "    final_loss = total_loss/total_weights\n",
    "    return final_loss, total_loss, total_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.813856Z",
     "iopub.status.busy": "2020-10-26T15:41:27.812726Z",
     "iopub.status.idle": "2020-10-26T15:41:27.816165Z",
     "shell.execute_reply": "2020-10-26T15:41:27.815571Z"
    },
    "papermill": {
     "duration": 0.045515,
     "end_time": "2020-10-26T15:41:27.816316",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.770801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_train_dataloader(train, cv_df, train_fold, valid_fold):\n",
    "    train_patients = cv_df.loc[cv_df.fold.isin(train_fold), 'StudyInstanceUID'].unique()\n",
    "    valid_patients = cv_df.loc[cv_df.fold.isin(valid_fold), 'StudyInstanceUID'].unique()\n",
    "\n",
    "    train_ = train.loc[train.StudyInstanceUID.isin(train_patients),:].reset_index(drop=True)\n",
    "    valid_ = train.loc[train.StudyInstanceUID.isin(valid_patients),:].reset_index(drop=True)\n",
    "\n",
    "    # train mode to do image-level subsampling\n",
    "    train_ds = RSNADataset(train_, 0.0, CFG['train_img_path'],  image_subsampling=True, transforms=get_train_transforms(), output_label=True) \n",
    "    valid_ds = RSNADataset(valid_, 0.0, CFG['train_img_path'],  image_subsampling=False, transforms=get_valid_transforms(), output_label=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=True,        \n",
    "        num_workers=CFG['num_workers'],\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=1,\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.878035Z",
     "iopub.status.busy": "2020-10-26T15:41:27.876937Z",
     "iopub.status.idle": "2020-10-26T15:41:27.905130Z",
     "shell.execute_reply": "2020-10-26T15:41:27.904516Z"
    },
    "papermill": {
     "duration": 0.060478,
     "end_time": "2020-10-26T15:41:27.905269",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.844791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_process(exam_pred, image_pred):\n",
    "    \n",
    "    negative_exam_for_pe_ix = CFG['exam_target_cols'].index('negative_exam_for_pe')\n",
    "    indeterminate_ix = CFG['exam_target_cols'].index('indeterminate')\n",
    "    both_no_ix = CFG['exam_target_cols'].index('both_no')\n",
    "    rv_lv_ratio_gte_1_ix = CFG['exam_target_cols'].index('rv_lv_ratio_gte_1')\n",
    "    rv_lv_ratio_lt_1_ix = CFG['exam_target_cols'].index('rv_lv_ratio_lt_1')\n",
    "    chronic_pe_ix = CFG['exam_target_cols'].index('chronic_pe')\n",
    "    acute_and_chronic_pe_ix = CFG['exam_target_cols'].index('acute_and_chronic_pe')\n",
    "    acute_pe_ix = CFG['exam_target_cols'].index('acute_pe')\n",
    "    rightsided_pe_ix = CFG['exam_target_cols'].index('rightsided_pe')\n",
    "    central_pe_ix = CFG['exam_target_cols'].index('central_pe')\n",
    "    leftsided_pe_ix = CFG['exam_target_cols'].index('leftsided_pe')\n",
    "    \n",
    "    # rule 1 or rule 2 judgement: if any pe image exist\n",
    "    has_pe_image = torch.max(image_pred, 1)[0][0] > 0\n",
    "    #print(has_pe_image)\n",
    "    \n",
    "    # rule 1-a: only one >= 0.5, the other < 0.5\n",
    "    rv_lv_ratios = exam_pred[:, [rv_lv_ratio_lt_1_ix, rv_lv_ratio_gte_1_ix]]\n",
    "    rv_lv_ratios_1_a = nn.functional.softmax(rv_lv_ratios, dim=1) # to make one at least > 0.5\n",
    "    rv_lv_ratios_1_a = torch.log(rv_lv_ratios_1_a/(1-rv_lv_ratios_1_a)) # turn back into logits\n",
    "    exam_pred[:, [rv_lv_ratio_lt_1_ix, rv_lv_ratio_gte_1_ix]] = torch.where(has_pe_image, rv_lv_ratios_1_a, rv_lv_ratios)\n",
    "    \n",
    "    # rule 1-b-1 or 1-b-2 judgement: at least one > 0.5\n",
    "    crl_pe = exam_pred[:, [central_pe_ix, rightsided_pe_ix, leftsided_pe_ix]]\n",
    "    has_no_pe = torch.max(crl_pe ,1)[0] <= 0 # all <= 0.5\n",
    "    #print(has_no_pe)\n",
    "    #assert False\n",
    "        \n",
    "    # rule 1-b\n",
    "    max_val = torch.max(crl_pe, 1)[0]\n",
    "    crl_pe_1_b = torch.where(crl_pe==max_val, 0.0001-crl_pe+crl_pe, crl_pe)\n",
    "    exam_pred[:, [central_pe_ix, rightsided_pe_ix, leftsided_pe_ix]] = torch.where(has_pe_image*has_no_pe, crl_pe_1_b, crl_pe)\n",
    "    \n",
    "    # rule 1-c-1 or 1-c-2 judgement: at most one > 0.5\n",
    "    ac_pe = exam_pred[:, [acute_and_chronic_pe_ix, chronic_pe_ix]]\n",
    "    both_ac_ch = torch.min(ac_pe ,1)[0] > 0 # all > 0.5\n",
    "    \n",
    "    # rule 1-c\n",
    "    ac_pe_1_c = nn.functional.softmax(ac_pe, dim=1) # to make only one > 0.5\n",
    "    ac_pe_1_c = torch.log(ac_pe_1_c/(1-ac_pe_1_c)) # turn back into logits\n",
    "    exam_pred[:, [acute_and_chronic_pe_ix, chronic_pe_ix]] = torch.where(has_pe_image*both_ac_ch, ac_pe_1_c, ac_pe)\n",
    "    \n",
    "    # rule 1-d\n",
    "    neg_ind = exam_pred[:, [negative_exam_for_pe_ix, indeterminate_ix]]\n",
    "    neg_ind_1d = torch.clamp(neg_ind, max=0)\n",
    "    exam_pred[:, [negative_exam_for_pe_ix, indeterminate_ix]] = torch.where(has_pe_image, neg_ind_1d, neg_ind)\n",
    "    \n",
    "    # rule 2-a\n",
    "    ne_inde = exam_pred[:, [negative_exam_for_pe_ix, indeterminate_ix]]\n",
    "    ne_inde_2_a = nn.functional.softmax(ne_inde, dim=1) # to make one at least > 0.5\n",
    "    ne_inde_2_a = torch.log(ne_inde_2_a/(1-ne_inde_2_a)) # turn back into logits\n",
    "    exam_pred[:, [negative_exam_for_pe_ix, indeterminate_ix]] = torch.where(~has_pe_image, ne_inde_2_a, ne_inde)\n",
    "    \n",
    "    # rule 2-b\n",
    "    all_other_exam_labels = exam_pred[:, [rv_lv_ratio_lt_1_ix, rv_lv_ratio_gte_1_ix,\n",
    "                                          central_pe_ix, rightsided_pe_ix, leftsided_pe_ix,\n",
    "                                          acute_and_chronic_pe_ix, chronic_pe_ix]]\n",
    "    all_other_exam_labels_2_b = torch.clamp(all_other_exam_labels, max=0)\n",
    "    exam_pred[:, [rv_lv_ratio_lt_1_ix, rv_lv_ratio_gte_1_ix,\n",
    "                  central_pe_ix, rightsided_pe_ix, leftsided_pe_ix,\n",
    "                  acute_and_chronic_pe_ix, chronic_pe_ix]] = torch.where(~has_pe_image, all_other_exam_labels_2_b, all_other_exam_labels)\n",
    "    \n",
    "    return exam_pred, image_pred\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:27.980726Z",
     "iopub.status.busy": "2020-10-26T15:41:27.979566Z",
     "iopub.status.idle": "2020-10-26T15:41:27.982762Z",
     "shell.execute_reply": "2020-10-26T15:41:27.982153Z"
    },
    "papermill": {
     "duration": 0.049117,
     "end_time": "2020-10-26T15:41:27.982879",
     "exception": false,
     "start_time": "2020-10-26T15:41:27.933762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, device, scaler, optimizer, train_loader):\n",
    "    model.train()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    loss_w_sum = 0\n",
    "\n",
    "    for step, (imgs, per_image_preds, locs, image_labels, exam_label, image_masks) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device).float()\n",
    "        per_image_preds = per_image_preds.to(device).float()\n",
    "        locs = locs.to(device).float()\n",
    "        image_masks = image_masks.to(device).float()\n",
    "        image_labels = image_labels.to(device).float()\n",
    "        exam_label = exam_label.to(device).float()\n",
    "\n",
    "        #print(image_labels.shape, exam_label.shape)\n",
    "        with autocast():\n",
    "            image_preds, exam_pred = model(per_image_preds, locs)   #output = model(input)\n",
    "            #print(image_preds.shape, exam_pred.shape)\n",
    "\n",
    "            loss, total_loss, total_weights = rsna_wloss_train(image_labels, exam_label, image_preds, exam_pred, image_masks, device)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            loss_sum += total_loss.detach().item()\n",
    "            loss_w_sum += total_weights.detach().item()\n",
    "\n",
    "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n",
    "\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()                \n",
    "\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                print(\n",
    "                    f'epoch {epoch} train step {step+1}/{len(train_loader)}, ' + \\\n",
    "                    f'loss: {loss_sum/loss_w_sum:.4f}, ' + \\\n",
    "                    f'time: {(time.time() - t):.4f}', end= '\\r' if (step + 1) != len(train_loader) else '\\n'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:28.059800Z",
     "iopub.status.busy": "2020-10-26T15:41:28.058387Z",
     "iopub.status.idle": "2020-10-26T15:41:28.062140Z",
     "shell.execute_reply": "2020-10-26T15:41:28.061556Z"
    },
    "papermill": {
     "duration": 0.050099,
     "end_time": "2020-10-26T15:41:28.062270",
     "exception": false,
     "start_time": "2020-10-26T15:41:28.012171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \n",
    "def valid_one_epoch(epoch, model, device, scheduler, val_loader, schd_loss_update=False):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    loss_w_sum = 0\n",
    "\n",
    "    for step, (imgs, per_image_preds, locs, image_labels, exam_label, image_masks) in enumerate(val_loader):\n",
    "        imgs = imgs.to(device).float()\n",
    "        per_image_preds = per_image_preds.to(device).float()\n",
    "        locs = locs.to(device).float()\n",
    "        image_masks = image_masks.to(device).float()\n",
    "        image_labels = image_labels.to(device).float()\n",
    "        exam_label = exam_label.to(device).float()\n",
    "\n",
    "        #print(image_labels.shape, exam_label.shape)\n",
    "        #with autocast():\n",
    "        image_preds, exam_pred = model(per_image_preds, locs)   #output = model(input)\n",
    "        #print(image_preds.shape, exam_pred.shape)\n",
    "        exam_pred, image_preds= post_process(exam_pred, image_preds)\n",
    "\n",
    "        loss, total_loss, total_weights = rsna_wloss_valid(image_labels, exam_label, image_preds, exam_pred, image_masks, device)\n",
    "\n",
    "        loss_sum += total_loss.detach().item()\n",
    "        loss_w_sum += total_weights.detach().item()          \n",
    "\n",
    "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
    "            print(\n",
    "                f'epoch {epoch} valid Step {step+1}/{len(val_loader)}, ' + \\\n",
    "                f'loss: {loss_sum/loss_w_sum:.4f}, ' + \\\n",
    "                f'time: {(time.time() - t):.4f}', end='\\r' if (step + 1) != len(val_loader) else '\\n'\n",
    "            )\n",
    "    \n",
    "    if schd_loss_update:\n",
    "        scheduler.step(loss_sum/loss_w_sum)\n",
    "    else:\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:28.143183Z",
     "iopub.status.busy": "2020-10-26T15:41:28.129123Z",
     "iopub.status.idle": "2020-10-26T15:41:28.146196Z",
     "shell.execute_reply": "2020-10-26T15:41:28.145596Z"
    },
    "papermill": {
     "duration": 0.055178,
     "end_time": "2020-10-26T15:41:28.146327",
     "exception": false,
     "start_time": "2020-10-26T15:41:28.091149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_label_consistency(checking_df):\n",
    "    # CHECKING CONSISTENCY OF POSITIVE EXAM LABELS\n",
    "    df = checking_df.copy()\n",
    "    print(df.shape)\n",
    "    df['positive_images_in_exam'] = df['StudyInstanceUID'].map(df.groupby(['StudyInstanceUID']).pe_present_on_image.max())\n",
    "\n",
    "    df_pos = df.loc[df.positive_images_in_exam >  0.5]\n",
    "    df_neg = df.loc[df.positive_images_in_exam <= 0.5]\n",
    "\n",
    "    rule1a = df_pos.loc[((df_pos.rv_lv_ratio_lt_1  >  0.5)  & \n",
    "                         (df_pos.rv_lv_ratio_gte_1 >  0.5)) | \n",
    "                        ((df_pos.rv_lv_ratio_lt_1  <= 0.5)  & \n",
    "                         (df_pos.rv_lv_ratio_gte_1 <= 0.5))].reset_index(drop = True)\n",
    "    rule1a['broken_rule'] = '1a'\n",
    "\n",
    "    rule1b = df_pos.loc[(df_pos.central_pe    <= 0.5) & \n",
    "                        (df_pos.rightsided_pe <= 0.5) & \n",
    "                        (df_pos.leftsided_pe  <= 0.5)].reset_index(drop = True)\n",
    "    rule1b['broken_rule'] = '1b'\n",
    "\n",
    "    rule1c = df_pos.loc[(df_pos.acute_and_chronic_pe > 0.5) & \n",
    "                        (df_pos.chronic_pe           > 0.5)].reset_index(drop = True)\n",
    "    rule1c['broken_rule'] = '1c'\n",
    "    # CHECKING CONSISTENCY OF NEGATIVE EXAM LABELS\n",
    "\n",
    "    rule1d = df_pos.loc[(df_pos.indeterminate        > 0.5) | \n",
    "                        (df_pos.negative_exam_for_pe > 0.5)].reset_index(drop = True)\n",
    "    rule1d['broken_rule'] = '1d'\n",
    "\n",
    "    rule2a = df_neg.loc[((df_neg.indeterminate        >  0.5)  & \n",
    "                         (df_neg.negative_exam_for_pe >  0.5)) | \n",
    "                        ((df_neg.indeterminate        <= 0.5)  & \n",
    "                         (df_neg.negative_exam_for_pe <= 0.5))].reset_index(drop = True)\n",
    "    rule2a['broken_rule'] = '2a'\n",
    "\n",
    "    rule2b = df_neg.loc[(df_neg.rv_lv_ratio_lt_1     > 0.5) | \n",
    "                        (df_neg.rv_lv_ratio_gte_1    > 0.5) |\n",
    "                        (df_neg.central_pe           > 0.5) | \n",
    "                        (df_neg.rightsided_pe        > 0.5) | \n",
    "                        (df_neg.leftsided_pe         > 0.5) |\n",
    "                        (df_neg.acute_and_chronic_pe > 0.5) | \n",
    "                        (df_neg.chronic_pe           > 0.5)].reset_index(drop = True)\n",
    "    rule2b['broken_rule'] = '2b'\n",
    "    # MERGING INCONSISTENT PREDICTIONS\n",
    "    errors = pd.concat([rule1a, rule1b, rule1c, rule1d, rule2a, rule2b], axis = 0)\n",
    "    \n",
    "    print('label in-consistency counts:', errors.shape)\n",
    "        \n",
    "    if errors.shape[0] > 0:\n",
    "        print(errors.broken_rule.value_counts())\n",
    "        print(errors)\n",
    "        assert False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:28.233021Z",
     "iopub.status.busy": "2020-10-26T15:41:28.231962Z",
     "iopub.status.idle": "2020-10-26T15:41:28.235136Z",
     "shell.execute_reply": "2020-10-26T15:41:28.235663Z"
    },
    "papermill": {
     "duration": 0.059908,
     "end_time": "2020-10-26T15:41:28.235825",
     "exception": false,
     "start_time": "2020-10-26T15:41:28.175917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "       \n",
    "def inference(model, device, df, root_path):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    ds = RSNADataset(df, 0.0, root_path,  image_subsampling=False, transforms=get_valid_transforms(), output_label=False)\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        ds, \n",
    "        batch_size=1,\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    patients = ds.get_patients()\n",
    "    \n",
    "    res_dfs = []\n",
    "    \n",
    "    for step, (imgs, per_image_preds, locs, img_num, index, seq_ix) in enumerate(dataloader):\n",
    "        imgs = imgs.to(device).float()\n",
    "        per_image_preds = per_image_preds.to(device).float()\n",
    "        locs = locs.to(device).float()\n",
    "        \n",
    "        index = index.detach().numpy()[0]\n",
    "        seq_ix = seq_ix.detach().numpy()[0,:]\n",
    "        \n",
    "        patient_filt = (df.StudyInstanceUID == patients[index])\n",
    "        \n",
    "        patient_df = pd.DataFrame()\n",
    "        patient_df['SOPInstanceUID'] = df.loc[patient_filt, 'SOPInstanceUID'].values[seq_ix]\n",
    "        patient_df['SeriesInstanceUID'] = df.loc[patient_filt, 'SeriesInstanceUID'].values # no need to sort\n",
    "        patient_df['StudyInstanceUID'] = patients[index] # single value\n",
    "        \n",
    "        for c in CFG['image_target_cols']+CFG['exam_target_cols']:\n",
    "            patient_df[c] = 0.0\n",
    "\n",
    "        #with autocast():\n",
    "        image_preds, exam_pred = model(per_image_preds, locs)   #output = model(input)\n",
    "        #print(image_preds.shape, exam_pred.shape)\n",
    "        \n",
    "        exam_pred, image_preds = post_process(exam_pred, image_preds)\n",
    "        \n",
    "        exam_pred = torch.sigmoid(exam_pred).cpu().detach().numpy()\n",
    "        image_preds = torch.sigmoid(image_preds).cpu().detach().numpy()\n",
    "\n",
    "        patient_df[CFG['exam_target_cols']] = exam_pred[0]\n",
    "        patient_df[CFG['image_target_cols']] = image_preds[0,:]\n",
    "        res_dfs += [patient_df]\n",
    "\n",
    "        '''\n",
    "        res_df = res_df.merge(patient_df, on=['SOPInstanceUID', 'StudyInstanceUID'], how='left')\n",
    "        '''\n",
    "        # naive slow version\n",
    "        '''\n",
    "        res_df.loc[patient_filt, CFG['exam_target_cols']] = exam_pred[0]\n",
    "        for si, sop_id in enumerate(sop_ids):\n",
    "            sop_filt = (patient_filt) & (res_df.SOPInstanceUID == sop_id)\n",
    "            res_df.loc[sop_filt, CFG['image_target_cols']] = image_preds[0, si]\n",
    "        '''\n",
    "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(dataloader)):\n",
    "            print(\n",
    "                f'Inference Step {step+1}/{len(dataloader)}, ' + \\\n",
    "                f'time: {(time.time() - t):.4f}', end='\\r' if (step + 1) != len(dataloader) else '\\n'\n",
    "            )\n",
    "                \n",
    "    res_dfs = pd.concat(res_dfs, axis=0).reset_index(drop=True)\n",
    "    res_dfs = df[['SOPInstanceUID', 'SeriesInstanceUID', 'StudyInstanceUID']].merge(res_dfs, on=['SOPInstanceUID', 'SeriesInstanceUID', 'StudyInstanceUID'], how='left')\n",
    "    print(res_dfs[CFG['image_target_cols']+CFG['exam_target_cols']].head(5))\n",
    "    print(res_dfs[CFG['image_target_cols']+CFG['exam_target_cols']].tail(5))\n",
    "    assert res_dfs.shape[0] == df.shape[0]\n",
    "    check_label_consistency(res_dfs)\n",
    "    \n",
    "    return res_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:28.304254Z",
     "iopub.status.busy": "2020-10-26T15:41:28.302696Z",
     "iopub.status.idle": "2020-10-26T15:41:28.305059Z",
     "shell.execute_reply": "2020-10-26T15:41:28.305646Z"
    },
    "papermill": {
     "duration": 0.041241,
     "end_time": "2020-10-26T15:41:28.305804",
     "exception": false,
     "start_time": "2020-10-26T15:41:28.264563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STAGE1_CFGS = [\n",
    "    {\n",
    "        'tag': 'stage1',\n",
    "        'model_constructor': RSNAImgClassifier,\n",
    "        'dataset_constructor': RSNADatasetStage1,\n",
    "        'output_len': len(CFG['interim_target_cols'])\n",
    "    },\n",
    "]\n",
    "\n",
    "STAGE1_CFGS_TAG = 'stage1'\n",
    "\n",
    "def get_stage1_columns():\n",
    "    \n",
    "    new_feats = []\n",
    "    for cfg in STAGE1_CFGS:\n",
    "        for i in range(cfg['output_len']):\n",
    "            f = cfg['tag']+'_'+str(i)\n",
    "            new_feats += [f]\n",
    "        \n",
    "    return new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:28.394390Z",
     "iopub.status.busy": "2020-10-26T15:41:28.393238Z",
     "iopub.status.idle": "2020-10-26T15:41:28.396130Z",
     "shell.execute_reply": "2020-10-26T15:41:28.396654Z"
    },
    "papermill": {
     "duration": 0.062015,
     "end_time": "2020-10-26T15:41:28.396815",
     "exception": false,
     "start_time": "2020-10-26T15:41:28.334800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def update_stage1_oof_preds(df, cv_df):\n",
    "    \n",
    "    res_file_name = STAGE1_CFGS_TAG+\"-train.csv\"    \n",
    "    \n",
    "    new_feats = get_stage1_columns()\n",
    "    for f in new_feats:\n",
    "        df[f] = 0\n",
    "    \n",
    "    if os.path.isfile(res_file_name):\n",
    "        df = pd.read_csv(res_file_name)\n",
    "        df = preprocess_DF(df)\n",
    "        print('img acc:', ((df[new_feats[0]]>0)==df[CFG['image_target_cols'][0]]).mean())\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    for fold, (train_fold, valid_fold) in enumerate(zip(CFG['train_folds'], CFG['valid_folds'])):\n",
    "        if fold < 0:\n",
    "            continue\n",
    "            \n",
    "        valid_patients = cv_df.loc[cv_df.fold.isin(valid_fold), 'StudyInstanceUID'].unique()\n",
    "        filt = df.StudyInstanceUID.isin(valid_patients)\n",
    "        valid_ = df.loc[filt,:].reset_index(drop=True)\n",
    "\n",
    "        image_preds_all_list = []\n",
    "        for cfg in STAGE1_CFGS:\n",
    "            valid_ds = cfg['dataset_constructor'](valid_, 0.0, CFG['train_img_path'],  image_subsampling=False, transforms=get_valid_transforms(), output_label=True)\n",
    "\n",
    "            val_loader = torch.utils.data.DataLoader(\n",
    "                valid_ds, \n",
    "                batch_size=CFG['stage1_valid_bs'],\n",
    "                num_workers=CFG['num_workers'],\n",
    "                shuffle=False,\n",
    "                pin_memory=False,\n",
    "                sampler=SequentialSampler(valid_ds)\n",
    "            )\n",
    "\n",
    "            device = torch.device(CFG['device'])\n",
    "            model = cfg['model_constructor']().to(device)\n",
    "            model.load_state_dict(torch.load('{}/model_{}'.format(CFG['stage_model_path'], cfg['tag'])))\n",
    "            model.eval()\n",
    "\n",
    "            image_preds_all = []\n",
    "            correct_count = 0\n",
    "            count = 0\n",
    "            for step, (imgs, mts, target) in enumerate(val_loader):\n",
    "                imgs = imgs.to(device).float()\n",
    "                mts = mts.to(device).float()\n",
    "                target = target.to(device).float()\n",
    "\n",
    "                image_preds = model(imgs, mts)   #output = model(input)\n",
    "                #print(image_preds[:,0], image_preds[:,0].shape)\n",
    "                #print(target, target.shape)\n",
    "                \n",
    "                if len(image_preds.shape) == 1:\n",
    "                    image_preds = image_preds.view(-1, 1)\n",
    "                \n",
    "                correct_count += ((image_preds[:,0]>0) == target[:,0]).sum().detach().item()\n",
    "                count += imgs.shape[0]\n",
    "                image_preds_all += [image_preds.cpu().detach().numpy()]\n",
    "                print('acc: {:.4f}, {}, {}, {}/{}'.format(correct_count/count, correct_count, count, step+1, len(val_loader)), end='\\r')\n",
    "            print()\n",
    "            \n",
    "            image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "            image_preds_all_list += [image_preds_all]\n",
    "        \n",
    "            del model, val_loader\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        image_preds_all_list = np.concatenate(image_preds_all_list, axis=1)\n",
    "        df.loc[filt, new_feats] = image_preds_all_list\n",
    "        \n",
    "    df.to_csv(res_file_name, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:28.474789Z",
     "iopub.status.busy": "2020-10-26T15:41:28.472691Z",
     "iopub.status.idle": "2020-10-26T15:41:28.475658Z",
     "shell.execute_reply": "2020-10-26T15:41:28.476259Z"
    },
    "papermill": {
     "duration": 0.050446,
     "end_time": "2020-10-26T15:41:28.476410",
     "exception": false,
     "start_time": "2020-10-26T15:41:28.425964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_stage1_test_preds(df):\n",
    "    \n",
    "    new_feats = get_stage1_columns()\n",
    "    for f in new_feats:\n",
    "        df[f] = 0\n",
    "    \n",
    "    image_preds_all_list = []\n",
    "    for cfg in STAGE1_CFGS:\n",
    "        test_ds = cfg['dataset_constructor'](df, 0.0, CFG['test_img_path'],  image_subsampling=False, transforms=get_valid_transforms(), output_label=False)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_ds, \n",
    "            batch_size=CFG['stage1_valid_bs'],\n",
    "            num_workers=CFG['num_workers'],\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "            sampler=SequentialSampler(test_ds)\n",
    "        )\n",
    "\n",
    "        device = torch.device(CFG['device'])\n",
    "        model = cfg['model_constructor']().to(device)\n",
    "        model.load_state_dict(torch.load('{}/model_{}'.format(CFG['stage_model_path'], cfg['tag'])))\n",
    "        model.eval()\n",
    "\n",
    "        image_preds_all = []\n",
    "        for step, (imgs, mts) in enumerate(tqdm(test_loader)):\n",
    "            imgs = imgs.to(device).float()\n",
    "            mts = mts.to(device).float()\n",
    "\n",
    "            image_preds = model(imgs, mts)   #output = model(input)\n",
    "            image_preds_all += [image_preds.cpu().detach().numpy()]\n",
    "            #print(imgs[0], image_preds[0,:]); break\n",
    "        \n",
    "        #continue\n",
    "        image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "        image_preds_all_list += [image_preds_all]\n",
    "        \n",
    "        del model, test_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    image_preds_all_list = np.concatenate(image_preds_all_list, axis=1)\n",
    "    df.loc[:,new_feats] = image_preds_all_list\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:28.547291Z",
     "iopub.status.busy": "2020-10-26T15:41:28.546204Z",
     "iopub.status.idle": "2020-10-26T15:41:40.946861Z",
     "shell.execute_reply": "2020-10-26T15:41:40.947524Z"
    },
    "papermill": {
     "duration": 12.441536,
     "end_time": "2020-10-26T15:41:40.947690",
     "exception": false,
     "start_time": "2020-10-26T15:41:28.506154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first part done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if CFG['train']:\n",
    "    seed_everything(SEED)\n",
    "    train_df = pd.read_csv(CFG['train_path'])\n",
    "    cv_df = pd.read_csv(CFG['cv_fold_path'])\n",
    "    cv_df = cv_df.sample(n=3500)\n",
    "    \n",
    "    # fold_studies = cv_df.loc[cv_df['fold'].isin([*CFG['train_folds'][0], *CFG['valid_folds'][0]]), 'StudyInstanceUID']\n",
    "    # train_df = train_df.loc[train_df['StudyInstanceUID'].isin(fold_studies), :]\n",
    "    \n",
    "    train_df = preprocess_DF(train_df)\n",
    "    cv_df = preprocess_DF(cv_df)\n",
    "    print(train_df.shape)\n",
    "    print(cv_df.shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_df = update_stage1_oof_preds(train_df, cv_df)\n",
    "    print('first part done')\n",
    "    # img must be sorted before feeding into NN for correct orders\n",
    "else:\n",
    "    #assert False, \"This kernel is for training only!\"\n",
    "    # read test file\n",
    "    \n",
    "    do_full=False\n",
    "    if path.exists('../input/rsna-str-pulmonary-embolism-detection/train') and not do_full:\n",
    "        test_df=pd.read_csv(CFG['test_path']).head(50)\n",
    "    else:\n",
    "        test_df=pd.read_csv(CFG['test_path'])\n",
    "\n",
    "    print(test_df.shape)\n",
    "    with torch.no_grad():\n",
    "        test_df = update_stage1_test_preds(test_df)\n",
    "\n",
    "    print('first part done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:41.120760Z",
     "iopub.status.busy": "2020-10-26T15:41:41.119056Z",
     "iopub.status.idle": "2020-10-26T15:41:41.125161Z",
     "shell.execute_reply": "2020-10-26T15:41:41.124521Z"
    },
    "papermill": {
     "duration": 0.143277,
     "end_time": "2020-10-26T15:41:41.125303",
     "exception": false,
     "start_time": "2020-10-26T15:41:40.982026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T15:41:41.206604Z",
     "iopub.status.busy": "2020-10-26T15:41:41.205461Z",
     "iopub.status.idle": "2020-10-26T15:41:41.938311Z",
     "shell.execute_reply": "2020-10-26T15:41:41.937631Z"
    },
    "papermill": {
     "duration": 0.777046,
     "end_time": "2020-10-26T15:41:41.938444",
     "exception": false,
     "start_time": "2020-10-26T15:41:41.161398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Step 1/1, time: 0.2722\n",
      "   pe_present_on_image  negative_exam_for_pe  indeterminate  both_no  \\\n",
      "0             0.469962              0.934129       0.065871  0.40263   \n",
      "1             0.454107              0.934129       0.065871  0.40263   \n",
      "2             0.391223              0.934129       0.065871  0.40263   \n",
      "3             0.400923              0.934129       0.065871  0.40263   \n",
      "4             0.417210              0.934129       0.065871  0.40263   \n",
      "\n",
      "   rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  chronic_pe  acute_and_chronic_pe  \\\n",
      "0           0.200673           0.24321    0.138554              0.057221   \n",
      "1           0.200673           0.24321    0.138554              0.057221   \n",
      "2           0.200673           0.24321    0.138554              0.057221   \n",
      "3           0.200673           0.24321    0.138554              0.057221   \n",
      "4           0.200673           0.24321    0.138554              0.057221   \n",
      "\n",
      "   acute_pe  leftsided_pe  central_pe  rightsided_pe  \n",
      "0  0.267038      0.301598    0.120414       0.249362  \n",
      "1  0.267038      0.301598    0.120414       0.249362  \n",
      "2  0.267038      0.301598    0.120414       0.249362  \n",
      "3  0.267038      0.301598    0.120414       0.249362  \n",
      "4  0.267038      0.301598    0.120414       0.249362  \n",
      "    pe_present_on_image  negative_exam_for_pe  indeterminate  both_no  \\\n",
      "45             0.339772              0.934129       0.065871  0.40263   \n",
      "46             0.441934              0.934129       0.065871  0.40263   \n",
      "47             0.446963              0.934129       0.065871  0.40263   \n",
      "48             0.451172              0.934129       0.065871  0.40263   \n",
      "49             0.459490              0.934129       0.065871  0.40263   \n",
      "\n",
      "    rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  chronic_pe  acute_and_chronic_pe  \\\n",
      "45           0.200673           0.24321    0.138554              0.057221   \n",
      "46           0.200673           0.24321    0.138554              0.057221   \n",
      "47           0.200673           0.24321    0.138554              0.057221   \n",
      "48           0.200673           0.24321    0.138554              0.057221   \n",
      "49           0.200673           0.24321    0.138554              0.057221   \n",
      "\n",
      "    acute_pe  leftsided_pe  central_pe  rightsided_pe  \n",
      "45  0.267038      0.301598    0.120414       0.249362  \n",
      "46  0.267038      0.301598    0.120414       0.249362  \n",
      "47  0.267038      0.301598    0.120414       0.249362  \n",
      "48  0.267038      0.301598    0.120414       0.249362  \n",
      "49  0.267038      0.301598    0.120414       0.249362  \n",
      "(50, 15)\n",
      "label in-consistency counts: (0, 17)\n",
      "                                  id     label\n",
      "0  df06fad17bc3_negative_exam_for_pe  0.934129\n",
      "1         df06fad17bc3_indeterminate  0.065871\n",
      "2     df06fad17bc3_rv_lv_ratio_gte_1  0.200673\n",
      "              id     label\n",
      "56  ec8da943ce56  0.446963\n",
      "57  011697fe8dd3  0.451172\n",
      "58  87264e009a34  0.459490\n",
      "(59, 2)\n"
     ]
    }
   ],
   "source": [
    "if CFG['train']:\n",
    "    for fold, (train_fold, valid_fold) in enumerate(zip(CFG['train_folds'], CFG['valid_folds'])):\n",
    "\n",
    "        train_loader, val_loader = prepare_train_dataloader(train_df, cv_df, train_fold, valid_fold)\n",
    "\n",
    "        device = torch.device(CFG['device'])\n",
    "        model = RSNAClassifier().to(device)\n",
    "        model.load_state_dict(torch.load('{}/model_{}'.format(CFG['model_path'], CFG['tag'])))\n",
    "        # model.load_state_dict(torch.load('{}/model_{}'.format(CFG['stage_model_path'], CFG['tag'])))\n",
    "        scaler = GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.1, step_size=1); schd_loss_update=False\n",
    "\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            train_one_epoch(epoch, model, device, scaler, optimizer, train_loader)\n",
    "            \n",
    "            torch.save(model.state_dict(),'{}/model_{}'.format(CFG['model_path'], CFG['tag']))\n",
    "            \n",
    "           #  with torch.no_grad():\n",
    "            #     valid_one_epoch(epoch, model, device, scheduler, val_loader, schd_loss_update=schd_loss_update)\n",
    "\n",
    "        torch.save(model.state_dict(),'{}/model_{}'.format(CFG['model_path'], CFG['tag']))\n",
    "        # model.load_state_dict(torch.load('{}/model_{}'.format(CFG['model_path'], CFG['tag'])))\n",
    "        \n",
    "\n",
    "        # prediction for oof\n",
    "        valid_patients = cv_df.loc[cv_df.fold.isin(valid_fold), 'StudyInstanceUID'].unique()\n",
    "        valid_ = train_df.loc[train_df.StudyInstanceUID.isin(valid_patients),:].reset_index(drop=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_pred_df = inference(model, device, valid_, CFG['train_img_path'])\n",
    "\n",
    "        target = valid_[CFG['image_target_cols']].values\n",
    "        pred = (val_pred_df[CFG['image_target_cols']].values > 0.5).astype(int)\n",
    "        print('Image PE Accuracy: {:.3f}'.format((target==pred).mean()*100))\n",
    "\n",
    "        loss = rsna_wloss_inference(valid_[CFG['image_target_cols']].values, \n",
    "                                    valid_[CFG['exam_target_cols']].values, \n",
    "                                    val_pred_df[CFG['image_target_cols']].values, \n",
    "                                    val_pred_df[CFG['exam_target_cols']].values, \n",
    "                                    list(valid_.groupby('StudyInstanceUID', sort=False)['SOPInstanceUID'].count()))\n",
    "\n",
    "        print('Validation loss = {:.4f}'.format(loss.detach().item()))\n",
    "\n",
    "        del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "        torch.cuda.empty_cache()\n",
    "    '''\n",
    "    train_loader, val_loader = prepare_train_dataloader(train_df, cv_df, np.arange(0, 20), np.array([]))\n",
    "    device = torch.device(CFG['device'])\n",
    "    model = RSNAClassifier().to(device)\n",
    "    scaler = GradScaler()   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.1, step_size=1); schd_loss_update=False\n",
    "\n",
    "    for epoch in range(CFG['epochs']):\n",
    "        train_one_epoch(epoch, model, device, scaler, optimizer, train_loader)\n",
    "        torch.save(model.state_dict(),'{}/model_{}'.format(CFG['model_path'], CFG['tag']))\n",
    "\n",
    "    torch.save(model.state_dict(),'{}/model_{}'.format(CFG['model_path'], CFG['tag']))\n",
    "    '''\n",
    "    \n",
    "else:\n",
    "    device = torch.device(CFG['device'])\n",
    "    model = RSNAClassifier().to(device)\n",
    "    model.load_state_dict(torch.load('{}/model_{}'.format(CFG['stage_model_path'], CFG['tag'])))\n",
    "    test_pred_df = inference(model, device, test_df, CFG['test_img_path'])       \n",
    "    test_pred_df.to_csv('kh_submission_raw.csv')\n",
    "\n",
    "    # transform into submission format\n",
    "    ids = []\n",
    "    labels = []\n",
    "\n",
    "    gp_mean = test_pred_df.loc[:, ['StudyInstanceUID']+[x for x in CFG['exam_target_cols'] if x not in ['both_no', 'acute_pe']]].groupby('StudyInstanceUID', sort=False).mean()\n",
    "    for col in [x for x in CFG['exam_target_cols'] if x not in ['both_no', 'acute_pe']]:\n",
    "        ids += [[patient+'_'+col for patient in gp_mean.index]]\n",
    "        labels += [gp_mean[col].values]\n",
    "\n",
    "    ids += [test_pred_df.SOPInstanceUID.values]\n",
    "    labels += [test_pred_df[CFG['image_target_cols']].values[:,0]]\n",
    "    ids = np.concatenate(ids)\n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    assert len(ids) == len(labels)\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission['id'] = ids\n",
    "    submission['label'] = labels\n",
    "    print(submission.head(3))\n",
    "    print(submission.tail(3))\n",
    "    print(submission.shape)\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.038374,
     "end_time": "2020-10-26T15:41:42.015526",
     "exception": false,
     "start_time": "2020-10-26T15:41:41.977152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033645,
     "end_time": "2020-10-26T15:41:42.083866",
     "exception": false,
     "start_time": "2020-10-26T15:41:42.050221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 58.977728,
   "end_time": "2020-10-26T15:41:43.375271",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-26T15:40:44.397543",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
